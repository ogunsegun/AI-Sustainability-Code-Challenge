{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76854ad",
   "metadata": {},
   "source": [
    "# Energy-Efficient Buildings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805eccb",
   "metadata": {},
   "source": [
    "Utilize technologies such as smart sensors, IoT devices, and building automation systems to optimize energy usage in residential, commercial, and industrial buildings, reducing energy consumption and carbon emissions.\n",
    "\n",
    "**How can Energy-Efficient Buildings reduce energy consumption and carbon and how can it be use in a AI or Machine Leaning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437d38d",
   "metadata": {},
   "source": [
    "*Energy-Efficient Buildings can reduce energy consumption and carbon emissions through various measures such as:*\n",
    "\n",
    "Optimized Heating, Ventilation, and Air Conditioning (HVAC) Systems: Energy-efficient HVAC systems regulate indoor temperature and air quality more efficiently, reducing energy usage and carbon emissions associated with heating and cooling.\n",
    "\n",
    "\n",
    "Smart Lighting Systems: Automated lighting systems with occupancy sensors and daylight harvesting capabilities adjust lighting levels based on natural light availability and occupancy, minimizing unnecessary energy usage.\n",
    "\n",
    "\n",
    "Building Envelope Improvements: Enhancements such as better insulation, high-performance windows, and reflective roofing materials reduce heat transfer, improving thermal comfort and reducing the need for heating and cooling energy.\n",
    "\n",
    "\n",
    "Energy-Efficient Appliances and Equipment: Installing energy-efficient appliances, such as ENERGY STAR-rated refrigerators and washing machines, and using high-efficiency office equipment and electronics can significantly reduce energy consumption.\n",
    "\n",
    "\n",
    "Building Automation and Controls: Utilizing building automation systems to optimize energy usage by coordinating HVAC, lighting, and other building systems based on occupancy patterns, time of day, and external conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b8269",
   "metadata": {},
   "source": [
    "*AI and machine learning can further enhance the energy efficiency of buildings by:*\n",
    "\n",
    "Predictive Maintenance: AI algorithms can analyze data from building systems to predict equipment failures and schedule maintenance proactively, ensuring optimal performance and energy efficiency.\n",
    "\n",
    "\n",
    "Occupancy Prediction: Machine learning models can analyze historical occupancy data, weather forecasts, and other factors to predict future occupancy patterns, allowing building systems to adjust accordingly and optimize energy usage.\n",
    "\n",
    "\n",
    "Optimized Energy Management: AI-based energy management systems can continuously analyze energy consumption data and dynamically adjust building systems to minimize energy waste while maintaining occupant comfort.\n",
    "\n",
    "\n",
    "Fault Detection and Diagnostics: Machine learning algorithms can detect anomalies in building performance data, such as unexpected energy spikes or inefficient equipment operation, enabling early detection and resolution of issues that impact energy efficiency.\n",
    "\n",
    "\n",
    "Personalized Comfort Settings: AI-driven building automation systems can learn occupants' preferences for temperature, lighting, and other environmental factors and adjust settings accordingly to optimize comfort and energy efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0d94e",
   "metadata": {},
   "source": [
    "# DATA Abstract\n",
    "\n",
    "This dataset was curated from an office building constructed in 2015 in Berkeley, California, which includes whole-building and end-use energy consumption, HVAC system operating conditions, indoor and outdoor environmental parameters, and occupant counts. \n",
    "The data was collected in three years from more than 300 sensors and meters for two office floors (each 2,325 m2) of the building. A three-step data curation strategy is applied to transform the raw data into the research-grade data: (1) cleaning the raw data to detect and adjust the outlier values and fill the data gaps; (2) creating the metadata model of the building systems and data points using the Brick schema; \n",
    "(3) describing the metadata of the dataset using a semantic JSON schema. This dataset can be used for various types of applications, including building energy benchmarking, load shape analysis, energy prediction, occupancy prediction and analytics, and HVAC controls to improve understanding and efficiency of building operations for reducing energy use, energy costs, and carbon emissions.\n",
    "\n",
    "# DATA Methods\n",
    "This dataset includes data of whole-building and end-use energy consumption, HVAC system operating conditions, indoor and outdoor environmental parameters, and occupant counts. The data was collected in three years from more than 300 sensors and meters for two office floors of the building. \n",
    "A three-step data curation strategy is applied to transform the raw data into the research-grade data: (1) cleaning the raw data to detect and adjust the outlier values and fill the data gaps; (2) creating the metadata model of the building systems and data points using the Brick schema; (3) describing the metadata of the dataset using a semantic JSON schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d399e7",
   "metadata": {},
   "source": [
    "# DATA SOURCE\n",
    "\n",
    "Hong, Tianzhen; Luo, Na; Blum, David; Wang, Zhe (2022). A three-year building operational performance dataset for informing energy efficiency [Dataset]. Dryad. https://doi.org/10.7941/D1N33Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8964444",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2579bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "82cc3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD Energy use data\n",
    "ENB2012_data= pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\ENB2012_data.CSV')\n",
    "\n",
    "#weather use data\n",
    "seattle_weather= pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\seattle_weather.CSV')\n",
    "\n",
    "# Load HVAC operational data\n",
    "rtu_ra_t = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_ra_t.CSV')\n",
    "hp_hws_temp = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\hp_hws_temp.CSV')\n",
    "rtu_sa_t_sp = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_sa_t_sp.CSV')\n",
    "rtu_sa_t = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_sa_t.CSV')\n",
    "rtu_ma_t = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_ma_t.CSV')\n",
    "rtu_oa_t = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_oa_t.CSV')\n",
    "rtu_sa_fr = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_sa_fr.CSV')\n",
    "rtu_oa_fr = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_oa_fr.CSV')\n",
    "rtu_oa_damper = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_oa_damper.CSV')\n",
    "rtu_econ_sp = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_econ_sp.CSV')\n",
    "rtu_sa_p_sp =pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_sa_p_sp.CSV')\n",
    "rtu_plenum_p = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_plenum_p.CSV')\n",
    "rtu_fan_spd = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\rtu_fan_spd.CSV')\n",
    "ashp_meter = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\ashp_meter.CSV')\n",
    "ashp_cw = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\ashp_cw.CSV')\n",
    "ashp_hw = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\ashp_hw.CSV')\n",
    "uft_fan_spd = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\uft_fan_spd.CSV')\n",
    "uft_hw_valve = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\uft_hw_valve.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "22efaa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mels_S</th>\n",
       "      <th>lig_S</th>\n",
       "      <th>mels_N</th>\n",
       "      <th>hvac_N</th>\n",
       "      <th>hvac_S</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/1/1 1:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>37.400002</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/1/1 1:15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>19.889999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/1/1 1:30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/1/1 1:45</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37.200001</td>\n",
       "      <td>18.889999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/1/1 2:00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>37.400002</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  mels_S  lig_S  mels_N     hvac_N     hvac_S  Unnamed: 6\n",
       "0  2018/1/1 1:00     1.2    0.2     7.5  37.400002  19.500000         NaN\n",
       "1  2018/1/1 1:15     1.3    0.2     6.8  37.500000  19.889999         NaN\n",
       "2  2018/1/1 1:30     1.1    0.2     7.4  38.000000  19.299999         NaN\n",
       "3  2018/1/1 1:45     1.2    0.2     7.7  37.200001  18.889999         NaN\n",
       "4  2018/1/1 2:00     1.1    0.2     7.3  37.400002  24.700001         NaN"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ele.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "92820991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['values'] = pd.to_numeric(df['values'], errors='coerce')\n",
    "ENB2012_data['date'] = pd.to_numeric(ashp_cw['date'], errors='coerce').isna()\n",
    "weatherHistory['date'] = pd.to_numeric(weatherHistory['date'], errors='coerce').isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7ac1546b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENB2012_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9b7505cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1461, 6)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seattle_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8a3f698b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m seattle_weather\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m=\u001b[39m \u001b[43mseattle_weather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(seattle_weather\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    " seattle_weather.shape= seattle_weather.shape.reshape(seattle_weather.shape.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0a3ac5fb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [768, 43979]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m Y\u001b[38;5;241m=\u001b[39m ENB2012_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Split data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train machine learning model to predict energy consumption\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [768, 43979]"
     ]
    }
   ],
   "source": [
    "#ashp_cw\n",
    "X =ENB2012_data.drop(columns=['X1'])\n",
    "Y= ENB2012_data['X1']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train machine learning model to predict energy consumption\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Use trained model for predictive energy management\n",
    "# For example, predict energy consumption for the next day based on weather forecast and historical data\n",
    "#LOAD Energy use data\n",
    "# ele= pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\Bldg59_clean data\\\\ele.CSV')\n",
    "predicted_energy_consumption = model.predict(seattle_weather)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
